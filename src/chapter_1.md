# はじめに

この冊子は[Rustプログラミング言語](https://www.rust-lang.org/ja)に興味を持ち、[プログラミング言語Rust日本語版](https://doc.rust-jp.rs/book-ja/)などの入門書を読み終わった人が、何かコマンドラインツールを作ってみたいと思ったときに参考にできるように、Rustを使ったプログラムの作成を一通り知ることができるように書かれたものです。

実際にプログラムを書くときにはさまざまなクレートを活用することになります。使えそうなクレートを見つけたらドキュメントを頼りに使い方を調べていく必要があります。この冊子ではドキュメントを調べる過程も少し見せながらプログラムを作っていきます。

Rustを使った簡単なプログラムとして簡易的なウェブクローラを作ります。ウェブクローラというのはウェブページのリンクをたどっていって、ウェブページを収集するプログラムのことです。ウェブクローラは訪問したウェブページを保存しますが、この冊子では簡単のためにHTMLとそれに付随するリソースの保存機能は実装しないことにします。

ウェブクローラを作るためには大まかに次の機能が必要になります。

1. HTTPクライアントとしてウェブページをGETする。
2. HTMLを解析して`<a>`要素を探す。
3. 訪問済みのウェブページを記憶してまだ訪問していないリンクをたどる。

1番目の機能は[`reqwest`](https://crates.io/crates/reqwest)クレートを使うことで簡単に実現できます。
2番目の機能は[`select`](https://crates.io/crates/select)クレートを使うことで実現できます。このクレートはHTMLを解析して要素を抜き出すことができます。
3番目の機能は幅優先探索を実装することで実現できます。ウェブページを頂点、リンクを辺とするグラフを考えます。幅優先探索を行って適当な数のページを取得したら終了するようにします。

なお、ここで作るウェブクローラはとても簡易的なもので不足している機能はいくつもあります。例えば、JavaScriptを実行できないので、動的にHTMLを書き換えるウェブページに対しては全てのリンクを抽出できません。Single Page Applicationに対しては全く無力になります。さらに、`iframe`要素を読み込むことはしないので、フレームを使ったページからのリンクの抽出も不完全になります。

この冊子は全9章からなります。第1章はこの章です。第2章と第3章ではウェブページを取得してリンクを抽出するプログラムを書きます。この段階では、`reqwest`クレートのとりあえず使ってみるために`main`関数にコードを書いていきます。第4章では第3章までに書いたコードをライブラリとして使えるように整えます。そして第5章でロギングと細々したエラー処理を加えます。幅優先探索の解説と実装は第6章と第7章で行います。第8章でリンクの抽出と幅優先探索を結合してクローラを完成させます。最後に第9章で全体を振り返ります。

各章ではコードを提示し、そのコードに解説を加えていく形で説明を進めていきます。章末ではその章で書いたソースコードへのリンクを提示します。章末で提示するソースコードは、GitHubの[リポジトリ](https://github.com/ShotaroTsuji/mini-crawler)に置きました。また、一部の章には本文で扱いきれなかったことを演習問題として付しました。
